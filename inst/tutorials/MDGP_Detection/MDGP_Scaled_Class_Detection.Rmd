---
title: "(2) Spectral Detection of MDGP-Scaled Classes"
author: "Daniel Gann"
date: "`r Sys.Date()`"
output: 
  learnr::tutorial:
runtime: shiny_prerendered
theme: simplex
highlight: espresso`
progressive: true
allow_skip: true
description: "The first part of the tutorial introduced theory and a new method to scale categorical raster data, that considers information retention and representativeness of the scaled classes. The second part of the tutorial evaluates the detection of the scaled classes from remotely sensed data."
bibliography: references.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/research-institute-for-nature-and-forest.csl
---

## Processing Environment

### Installation of Required Packages

The required packages for this tutorial that will be installed together with their dependencies:

- landscapeScaling (dep.: terra, sf, compositions)
- caret

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)

# set up color scheme 
col12 <- c('#882255','#CC6677','#332288','#DDCC77','#117733','#88CCEE','#44AA99','#999933','#AA4499','#000000','#FFFFFF','#888888')
 
# install missing packages
packages_installed <- rownames(installed.packages())

# required package names from CRAN
packages <- c('remotes','devtools','terra','sf','leaflet','compositions','caret','BAMMtools')

# install missing packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages],repo = 'https://cran.uni-muenster.de/', dependencies = TRUE)
}

# install latest updates of landscapeScaling version
devtools::install_github("gannd/landscapeScaling", force=TRUE)

print('All required packages were installed')

# load libraries
library(terra)
library(scales)
library(landscapeScaling)
library(caret)
```

#### *The R package {landscapeScaling}*

The package {landscapeScaling} provides the methods and functions to upscale categorical raster data using the Multi-Dimensional Grid-Point scaling method by @Gann_2019. The method generates a new classification scheme on the basis of user desired class label precision of mixed classes and representativeness of the scaled classes across the landscape of interest. 

The scaling procedure creates scaled categorical raster maps with mixed classes, a corresponding continuous raster with compositional information retention calculations for each scaled grid cell, class-specific and landscape-level mean and standard deviation of information retention.The functions for MDGP-Scaling can be divided into two types of functions. The low-level functions follow a step-wise procedure of the scaling process. The high-level function 'mdgp_scale_raster' nests several functions to produce a scaled product from the raw categorical raster input. We will explore first the step-wise procedure before using the nested functions.

The current version of {landscapeScaling} was installed from [GitHub](https://github.com/) with devtools (devtools::install_github("gannd/landscapeScaling") during the installation of this tutorial.

### Verify Working Directory
```{r, wd-verify, exercise=TRUE, eval=FALSE}
# get the working directory
getwd()

# get the {terra} package temp folder options 
terraOptions()
```


**Check the working directory. This location will change every time you run the chunk -- try it. Therefore, we will have to set our working directory explicitly in every chunk where write data for subsequent exercises, and when we read the data.**


## Scaling of Real Landscapes

The scaling of categorical data models that represent real landscapes can be computationally very demanding. To determine the optimal scaling parameters for specific cases the user should answer three questions that will lead to selecting the parameters that optimize the classification scheme for its specific purpose.


If the scaling has the objective to detect the scaled classes from lower resolution data (e.g.,  to detect change over time using various RS data products with different spatial and spectral resolution), then the detection probability and accuracy of class detection should be considered in the parameter selection for precision and representativeness.

If the goal is to extract biophysical variables from coarser remotely sensed data, the precision of class mixes might be the most important parameter, especially when the landscape is heterogeneous with regard to the biophysical variable of interest.  
  
Is a specific grid alignment of impertance? The detection of scaled classes from a specific sensor (e.g., Landsat Grid) might require a scaling proceses that best captures the mixed pixels that are captured by the sensor. 

On the other hand, if the goal is to generate classification schemes that best represent random lcations in a landscape, then random origin of sampling units would better capture the representativeness of the classification scheme. In that case a spatial sampling design could be implemented to generate representative classes at different precision levels.

The example of this tutorial aims at the detection of scaled classes form a medium-resolution multispectral sensor. 

----

### Exercise 1 - Scaling of a Wetland Landscape

Study Area: A small subset of a wetland in Water Conservation Area 3A within the greater Everglades ecosystem complex. The study area is a healthy landscape with the typical ridge and slough pattern of alternating sawgrass ridges and deep water slough habitat.

The study area was mapped from 2010 and 2013 WorldView 2 (WV2) bi-season data acquired during wet conditions in November 2010 and dry conditions in May 2013 @Gann_Richards_2022.

The plant communities that were mapped from WV 2 are:
```{r, load-pc-lut, eval=TRUE, include=TRUE}
print(read.csv(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_13_classes_LUT.csv')))
```
The original classes were reclassified to simplify the classification scheme for this exercise. The reclassified map has five classes that are reclassified according to the reclass table.

```{r, load-rcl-lut, eval=TRUE, include=TRUE}
print('The classes are reclassfied to: ')
print(read.csv(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_RCL.csv')))

print('The reclassified map LUT: ')
print(read.csv(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_5_classes_LUT.csv')))
```

----

```{r, map-reclass, eval=FALSE, exercise=TRUE, include=TRUE}
## Reclassify the original Plant Community Map to Morphological Classes 

# set working directory
setwd('')

# load map 
veg_map <- terra::rast(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_wv2.tif'))
lut13 <- read.csv(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_13_classes_LUT.csv'))
levels(veg_map) <- lut13
print(veg_map)

# load the reclassification table
rcl <- read.csv(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_RCL.csv'))

# reclassify the map
veg_map_rcl <- terra::classify(veg_map,rcl[,c(1,3)])
lut5 <- read.csv(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_5_classes_LUT.csv'))
levels(veg_map_rcl) <- lut5

terra::writeRaster(veg_map_rcl,paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_5_classes.tif'),overwrite=TRUE)
x11();terra::plot(veg_map_rcl)
```

----

**Questions Ex. 1**

**What is the spatial resolution of the original map?**

**What is the scale factor if we want to scale this map to Landsat 30 m resolution?**

**What is the scale factor if we want to scale this map to Sentinel 20 m resolution?**

**What is the scale factor if we want to scale this map to MODIS 250 m resolution?**

----

```{r, questions-1-1-response, exercise=TRUE}
print('Answers: ')
```

----

Generate the relative abundance of classes with scale factor 15. The relative abundance data frame will be saved to .csv to be used in the following chunks.

```{r, sf-rel-abund, exercise=TRUE, exercise.lines=25, eval=FALSE, fig.show='hide'}
# set working directory
setwd('')

# load map 
veg_map <- terra::rast(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/plant_communities_5_classes.tif'))
classField <- 'class'

# subset the map to an area that captures the overall pattern of the landscape
veg_map <- terra::crop(veg_map,terra::ext(518000,520000,2859000,2861000))

# set the scale factor
sf <- 15

# ======= DO NOT MODIFY BEYOND THIS LINE =======

# calculate the relative abundance
system.time(rel_abund <- landscapeScaling::relative_abundance_scaled_grid(veg_map,class_field=classField,scale_factor=sf))

# write relative abundance to .csv file
write.csv(rel_abund,file=paste0('./pc5_sf',sf,'_rel_abund.csv'),row.names = FALSE)
```

----

**Questions**

**What are the expected dimensions (number of rows and columns) of the output grid?**
** ... ?**

```{r, questions-4-2-response, exercise=TRUE}
print('Answers: ')
```
----

Explore the effects of class-label precision (parts) and representativeness on compositional information retention.
parts: 1 - 5
representativeness: 0, 1, 5, 10, 20

Explore the scaled class distribution and information retention for a few scaled maps.
Note the effects of precision, representativeness and information retentio nthreshold on class number mean IR, 
**How does precision (parts) affect mean IR? ?**

```{r, map-scale, exercise=TRUE, exercise.lines=50, eval=FALSE, fig.show='hide'}
## Explore the effects of class-label precision (parts) and representativeness on compositional information retention.
## parts: 1 - 5
## representativeness: 0, 1, 5, 10, 20
# --------
# set working directory
setwd('')

# load relative abundance
rel_abund <- read.csv('./pc5_sf15_rel_abund.csv')
print(head(rel_abund))

# set output prefix
prfx <- 'pc5_sf15_'

# set parts between 2 and 5 corresponding to 50% up to 20% class label proportion (precision)
prts <- 2

# set representativeness, monotypic class, and cell-level information  retention thresholds 
rpr_th <- 10
mono_th <- 90
ir_th <- 50

# ======= DO NOT MODIFY BEYOND THIS LINE =======

# classify relative abundance samples to multi-dimensional grid points with no restrictions on the representativeness threshold or monotypic class threshold
mdgp_result <- landscapeScaling::mdgp_scale(x=rel_abund,parts=prts,rpr_threshold=rpr_th,monotypic_threshold=mono_th,ir_threshold=ir_th)
print(mdgp_result)

# write the scaled data frame to .rds file
saveRDS(mdgp_result,file=paste0('./',prfx,'prts',prts,'_rpr',rpr_th,'_mono',mono_th,'.rds'))
# -----------------------------------------------
# convert classified points and location-specific information retention to raster
mdgp_raster <- landscapeScaling::scaling_result_to_raster(scaling_result=mdgp_result,class_name_field='class_name',scale_factor=15)
# -----------------------------------------------
# plot the scaled map
x11();terra::plot(mdgp_raster[[1]],col=col12,mar=c(1.5,1.5,1.5,8),
            main=paste0('Scaled Classes: parts=',prts,'; rpr=',rpr_th,'; mono=',mono_th),cex.main = 1.2,
            plg=list( title = "Class Name",title.cex = 1, cex = 1),
            pax=list(cex.axis = 1 ))

# plot information retention of the scaled map
x11();terra::plot(mdgp_raster[[2]],col=gray.colors(20,start=0.1,end=1),mar=c(1.5,1.5,1.7,8),
            main=paste0('Information Retention for ',prts,' parts'),cex.main = 1.2,
            plg=list( title = "IR %",title.cex = 1, cex = 1),
            pax=list(cex.axis = 1 ))
# -----------------------------------------------
# print the class-specific and landscape scale summary statistics 
print(mdgp_raster[[3]])

# write scaled results to .tif
terra::writeRaster(mdgp_raster[[1]],file=paste0('./',prfx,'prts',prts,'_rpr',rpr_th,'_mono',mono_th,'_class.tif'))
```

**Questions**

**How does precision (parts) affect mean IR? ?**
**How does representativeness threshold affect mean IR?**
**How does information retention threshold affect class-specific and mean IR?**
```{r, questions-4-3-response, exercise=TRUE}
print('Answers: ')
```

## Detection of Scaled Classes from Multi-spectral Data

Objective: Explore the detectability of the differently scaled classes in the previous exercise from multi-spectral Landsat data.  The fine-resolution map was scaled to 30 m resolution using different label precision and representativeness combinations.

Select the map you want to determine the class detectability first. 

Important factors to consider when scaling: 

- The actual grid origin of the multi-spectral data needs to be used for relative abundance calculations. 

----

### Exercise 2: Detection of Scaled Classes from Landsat Data

In the last exercise we will test the detection accuracy of the scaled classes from Landsat multi-spectral data. The data set we are using is a Landsat 5 scene from 2011-11-10. The image was subset to the study area that was mapped from the 2010 and 2013 WorldView bi-seasonal data.

In our previous scaling exercise (Exercise 3) the Landsat grid was used in the scaling procedure and the Landsat pixels are aligned with the scaling results. 

Processing and Analysis Steps:
(1) extract signatures for all classes for centroids of the scaled map
(2) use random forest classifier to evaluate the detectability of the classes from the spectral signatures
(3) predict the map from spectral data

Accuracy Assessment
(1) model-based cross-validation accuracy
(2) partial-credit weighted accuracy

----

Explore the spectral data: We will load the subset Landsat scene and plot 2 band combinations

```{r, ls-inspect, exercise=TRUE, eval=FALSE, fig.show='hide'}
# set working directory
setwd('')

# load spectral Landsat data
ls <- terra::rast(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/L5TM_20111110_atmcor_sub.tif'))

# plot RGB of band combination 5,4,3.
x11();terra::plotRGB(ls, 5, 4, 3, stretch="hist")
```

---

Evaluate the detectability of the scaled classes from .

The next block of code will:

- load the scaled map with mixed class labels
- convert the map to points
- extract spectral signatures for each 30 m grid cell from the Landsat stack
- evaluate the class separability using cross-validated random forest models
- calculate the partial-credit weighted accuracy

The parameters that need to be set for the random forest classifier training

```{r, sig-eval, exercise=TRUE, eval=FALSE, fig.show='hide'}
# set working directory
setwd('')

# load sourced function
source(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/functions/partial_credit_weighted_accuracy.R'))

# landsat image
ls_nme <- 'L5TM_20111110_atmcor_sub.tif'

# scaled map name to evaluate
map_nme <- 'pc5_sf15_prts1_rpr0_mono100_class.tif'

## set random forest parameters
# number of trees
nTree <- 200

# training control
trCtrl <- caret::trainControl(
		method = 'cv',
		number = 5,
		classProbs= TRUE,
		allowParallel = TRUE,
		verbose = TRUE,
		savePredictions = TRUE)

# variable retention sizes
gridTune <- expand.grid(mtry = c(2:4))
nrow(gridTune)

# ========== DO NOT MODIFY BEYOND THIS LINE ==========

# load spectral Landsat data
spc.rst <- terra::rast(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/',ls_nme))

# load scaled map and convert to vector
map_class <- terra::rast(paste0(R.home(),'/library/mdgpTutorial/tutorials/MDGP_Detection/data_raw/',map_nme))
map.pnt <- terra::as.points(map_class, na.rm=TRUE)

# extract signature and join to class info
trnDat <- as.data.frame(terra::extract(spc.rst, map.pnt, bind=TRUE))
head(trnDat)
# -----------------------------------------------

# CROSS-VALIDATED RANDOM FOREST MODEL

mdlFit <- caret::train(trnDat[,2:7],as.character(trnDat$class_name),trControl = trCtrl, metric='Accuracy', method='rf', tuneGrid=gridTune, ntree=nTree, importance=TRUE)
print(mdlFit)
# -----------------------------------------------

# MODEL-BASED CROSS-VALIDATED ACCURACY ESTIMATES

# evaluate confusion matrix and write to file
mtxCnf.cv <- confusionMatrix(prdCV$pred,prdCV$obs)

# write class-specific evaluation and confusion matrix to file
write.table(mtxCnf.cv$byClass,paste0('./',prfx,'_mtxCnf_stats.csv'))
write.table(mtxCnf.cv$table,paste0('./',prfx,'_mtxCnf.csv'))
# -----------------------------------------------

# MODEL-BASED CROSS-VALIDATED PARTIAL-CREDIT WEIGHTED ACCURACY ESTIMATES

# uses the class-label agreement as weights for partial credit
# sourced functions: partial_credit_weighted_accuracy.R in /functions folder

# read cross-validated confusion matrix
mtxCnf <- mtxCnf.cv$table

# vectorize the weighting function
prtlCrdtWghts_V <- Vectorize(prtlCrdtWghts,vectorize.args = c('r_nme','c_nme'))

# generate weight matrix
mtxCnf_wght <- outer(rownames(mtxCnf),colnames(mtxCnf), prtlCrdtWghts_V)

# weight adjusted accuracy
wghtAcc <- wghtAdjAcc(cm=mtxCnf,wm=mtxCnf_wght)

# calculate weighted accuracies and confidence intervals
oaCV_wght <-  round(wghtAcc$sum.naive, 4)
ciAlpha <- ci(wghtAcc$sum.var, wghtAcc$sum.n,.05)
oaCV_wght_CIL <- round((wghtAcc$sum.naive-ciAlpha),4)
oaCV_wght_CIU <- round((wghtAcc$sum.naive+ciAlpha),4)
```

```{r, spec-eval, exercise=TRUE, eval=FALSE, fig.show='hide'}
# set working directory
setwd('')

# load scaled map and associated information retention layer
map_scl <- terra::rast('./[SCALED_MAP_NAME].tif')

# load information retention raster and calculate landscape level mean
map_infRtn <- terra::rast('./[SCALED_MAP_IRC_NAME].tif')
print(infRtnRL <- cellStats(map_infRtn, 'mean'))
```

Repeat the exercise for the other scaling results (precision and representativness threshold combinations) 

---

**Questions**

**How did increased precision of class-labels affect the detection accuracy from Landsat data?**
**How did increased representativeness affect the detection accuracy from Landsat data?**
**What are the trade-offs?**
```{r, questions-2-1-response, exercise=TRUE}
print('Answers: ')
```

----

## Acknowledgements

This tutorial and the package **landscapeScaling** rely heavily on functions from R packages **terra** [@terra], **sf** [@sf_1, @sf_2] **compositions** [@compositions], and **partitions** [@partitions].

## References {-}

<div id="refs"></div>

